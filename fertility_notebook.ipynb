{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1586e42",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7423c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d882ae3",
   "metadata": {},
   "source": [
    "Please note, we will be collaborating via Git. Please find our project at https://github.com/ppich1169/fertilityProjectCs109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461283f",
   "metadata": {},
   "source": [
    "# Milestone 1: Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07556bb7",
   "metadata": {},
   "source": [
    "Over the past fifty years, fertility rates in the US have plummeted and are currently at a historic low. Conversations about why fertility has fallen so substantially and how we can address the implications of this shift for government programs like social security have been quite salient in recent public discourse and in the 2024 election cycle. \n",
    "\n",
    "Interestingly, there is significant variation in fertility rates across US states. We’d like to understand the relative importance of various factors in determining a state’s fertility rate. \n",
    "\n",
    "We plan to run a multiple regression of fertility rate (can get state-by-state here from the CDC’s National Center for Health Statistics) on a number of regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d422fe2",
   "metadata": {},
   "source": [
    "**Goal:** Create a regression that can predict the fertility rate of a state. Then, analyze coefficients and/or use causal inference to understand why fertility rate is going down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2306c",
   "metadata": {},
   "source": [
    "# Milestone 2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091b7ea",
   "metadata": {},
   "source": [
    "## 1. Access the data that you will be using for the final project by downloading, collecting, or scraping* from the relevant source(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6af71",
   "metadata": {},
   "source": [
    "### Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ab7e9",
   "metadata": {},
   "source": [
    "Our response variable is **fertility rate by state over time** which can be found at https://www.cdc.gov/nchs/pressroom/sosmap/fertility_rate/fertility_rates.htm. \n",
    "\n",
    "We accessed it via download and saved it as `fertility_rate_census.csv`. \n",
    "\n",
    "Please note, fertility rate is defined as  **total number of births per 1,000 women aged 15-44** and our dataset looks at fertility rate for each of the 50 states over 9 years (2014-2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4bfa7",
   "metadata": {},
   "source": [
    "### Predictors\n",
    "_We used our previous knowledge and assumptions to create an **X** dataset of predictors that we believe may influence fertility rates_\n",
    "\n",
    "Because fertility rate is evaluated statewide , and states vary significantly in population size, we have decided that for all of the predictors, we are going to essentially **normalize** them by looking at the percentage of each state that fall into a specific category. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0005638",
   "metadata": {},
   "source": [
    "**ISABELLA SECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We care about basic demographic data which we downloaded get from the **census** at [**THIS LINK INSERT HERE**]\n",
    "\n",
    "Here is the census data we consider important (based on our own subjective opinions):\n",
    "- race\n",
    "- socio economic status (household income) - percentage of households below the poverty line\n",
    "- education level - share that are high school graduates \n",
    "- immigration status\n",
    "\n",
    "And obviously we need **age**, **sex** , **year** , and **state**  in order to aggregate our data\n",
    "\n",
    "We accessed it by [**SCRAPING (CODE BELOW) / DOWNLOADING**] and saved it in `dataset_name.csv` in our data folder\n",
    "\n",
    "Some things to consider include: [**INSERT HERE**] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also care about religion, political makeup, and whether certain abortion laws are in place (all of which are not in the census). We will find them different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00aeee",
   "metadata": {},
   "source": [
    "**PETER SECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576fc93",
   "metadata": {},
   "source": [
    "We decided to determine people's **religiousness** based off of [**INSERT HERE**] which can be found at [**INSERT LINK HERE**]\n",
    "\n",
    "We accessed it by [**SCRAPING (CODE BELOW) / DOWNLOADING**] and saved it in `dataset_name.csv` in our data folder\n",
    "\n",
    "Some things to consider include: [**INSERT HERE**] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b77098",
   "metadata": {},
   "source": [
    "**ELIZA SECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ce4a9",
   "metadata": {},
   "source": [
    "We decided to determine people's **political orienation** based off of [**INSERT HERE**] which can be found at [**INSERT LINK HERE**]\n",
    "\n",
    "We accessed it by [**SCRAPING (CODE BELOW) / DOWNLOADING**] and saved it in `dataset_name.csv` in our data folder\n",
    "\n",
    "Some things to consider include: [**INSERT HERE**] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7f12c",
   "metadata": {},
   "source": [
    "**MAIA SECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98418d",
   "metadata": {},
   "source": [
    "We decided to determine state's **abortion laws** based off of how late into pregnancy, abortion is legally allowed which can be found at https://lawatlas.org/datasets/abortion-bans. We chose this dataset because it is the only one on the internet showing abortion bans in the 2014-2022 time frame and how they change (most just show abortion bans now)\n",
    "\n",
    "We accessed it by downloading it, converting from xlsx to csv, and saved it in `abortion_data.csv` in our data folder\n",
    "\n",
    "The main thing to consider is that **just because abortion is legal, doesn't mean it is accessible**. Many states may technically allow abortion but only have one clinic, so its not attainable. That said, we have chosen this metric (when is abortion legal), to coincide with current political debate about whether abortion should be legalized. \n",
    "\n",
    "There will be significant preprocessing required as the data is in format `Effective Date`, `Valid Through Date` for each law which must simply be converted into year (whichever law was the majority of the year), and each ban `6 weeks`, `8 weeks` etc is categorical! It would make more sense to simply make a variable listing the latest week aborition is legal (0,6,8,12,52 etc).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data into a Jupyter notebook and understand the data by examining, among other characteristics of interest, data missingness, imbalance, and scaling issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues we preliminary have considered before even inspecting the data includes:\n",
    "\n",
    "\n",
    "- **under reporting immigration status**: via google, people tend to underreport whether they are immigrants. This is potentially a missingness issue\n",
    "\n",
    "-  **multicollinearity**: There is most likely a relationship between racial background / household income and an individual's birth country (immigration status) so we can't use both as predictors in the same equation. We don't know how strong this correlation will be so are not worried yet, but would love to talk about it with a TF\n",
    "\n",
    "- **is this just too much data??**: looking at each of these attributes for each state for each year may just be too many dimensions. Is there really a big difference accross years? Should we just look at 1? If so, which? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import and inspect each dataset, looking for missingness, imbalance, and scaling issues!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ebdcb",
   "metadata": {},
   "source": [
    "### Fertility Rate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR              0\n",
      "STATE             0\n",
      "FERTILITY RATE    0\n",
      "BIRTHS            0\n",
      "URL               0\n",
      "dtype: int64\n",
      "              YEAR  FERTILITY RATE         BIRTHS\n",
      "count   451.000000      451.000000     451.000000\n",
      "mean   2018.008869       60.057871   75783.962306\n",
      "std       2.588850        6.420758   86837.134690\n",
      "min    2014.000000       44.300000    5133.000000\n",
      "25%    2016.000000       56.000000   21758.500000\n",
      "50%    2018.000000       60.200000   55971.000000\n",
      "75%    2020.000000       63.500000   86486.000000\n",
      "max    2022.000000       80.000000  502879.000000\n"
     ]
    }
   ],
   "source": [
    "fertility_rate = pd.read_csv('data/fertility_rate_census.csv')\n",
    "print(fertility_rate.isna().sum(axis=0))\n",
    "fertility_rate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016931d7",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**:\n",
    "\n",
    "**Imbalance**:\n",
    "\n",
    "**Scaling**:\n",
    "\n",
    "**Other**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv('data/')\n",
    "print(census_data.isna().sum(axis=0))\n",
    "census_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276f4f3",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**:\n",
    "\n",
    "**Imbalance**:\n",
    "\n",
    "**Scaling**:\n",
    "\n",
    "**Other**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaf37b",
   "metadata": {},
   "source": [
    "### Religion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_data = pd.read_csv('data/')\n",
    "print(religion_data.isna().sum(axis=0))\n",
    "religion_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b6996",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**:\n",
    "\n",
    "**Imbalance**:\n",
    "\n",
    "**Scaling**:\n",
    "\n",
    "**Other**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741289e",
   "metadata": {},
   "source": [
    "### Politics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_data = pd.read_csv('data/')\n",
    "print(politics_data.isna().sum(axis=0))\n",
    "politics_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47016b",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**:\n",
    "\n",
    "**Imbalance**:\n",
    "\n",
    "**Scaling**:\n",
    "\n",
    "**Other**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a65ab",
   "metadata": {},
   "source": [
    "### Abortion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be40b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_data = pd.read_csv('data/abortion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29abc0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>latest_abortion</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  latest_abortion  year\n",
       "0  Alabama               20  2018\n",
       "2  Alabama               20  2019\n",
       "3  Alabama               20  2022\n",
       "4   Alaska               40  2018\n",
       "5  Arizona               18  2018"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"State\",\"Effective Date\",\"Valid Through Date\",\"Bans_gest_4 weeks postfertilization (6 weeks LMP) \" ,\"Bans_gest_6 weeks postfertilization (8 weeks LMP) \" ,\"Bans_gest_8 weeks postfertilization (10 weeks LMP)\",\"Bans_gest_10 weeks postfertilization (12 weeks LMP) \" ,\"Bans_gest_12 weeks postfertilization (14 weeks LMP)\",\"Bans_gest_13 weeks postfertilization (15 weeks LMP)\",\"Bans_gest_16 weeks postfertilization (18 weeks LMP) \",\"Bans_gest_18 weeks postfertilization (20 weeks LMP)\",\"Bans_gest_19 weeks postfertilization (21 weeks LMP)\",\"Bans_gest20 weeks postfertilization (22 weeks LMP)\",\"Bans_gest_21 weeks postfertilization (23 weeks LMP) \" ,\"Bans_gest_22 weeks postfertilization (24 weeks LMP)\",\"Bans_gest_24 weeks postfertilization (26 weeks LMP)\",\"Bans_gestViability\",\"Bans_gest_Fetus is capable of feeling pain\",\"Bans_gest_3rd trimester\"]\n",
    "abortion_data = abortion_data[columns]\n",
    "new_names = {\n",
    "    \"State\": \"state\",\n",
    "    \"Effective Date\": \"start\",\n",
    "    \"Valid Through Date\": \"end\",\n",
    "    \"Bans_gest_4 weeks postfertilization (6 weeks LMP) \": \"4\",\n",
    "    \"Bans_gest_6 weeks postfertilization (8 weeks LMP) \": \"6\",\n",
    "    \"Bans_gest_8 weeks postfertilization (10 weeks LMP)\": \"8\",\n",
    "    \"Bans_gest_10 weeks postfertilization (12 weeks LMP) \": \"10\",\n",
    "    \"Bans_gest_12 weeks postfertilization (14 weeks LMP)\": \"12\",\n",
    "    \"Bans_gest_13 weeks postfertilization (15 weeks LMP)\": \"13\",\n",
    "    \"Bans_gest_16 weeks postfertilization (18 weeks LMP) \": \"16\",\n",
    "    \"Bans_gest_18 weeks postfertilization (20 weeks LMP)\": \"18\",\n",
    "    \"Bans_gest_19 weeks postfertilization (21 weeks LMP)\": \"19\",\n",
    "    \"Bans_gest20 weeks postfertilization (22 weeks LMP)\": \"20\",\n",
    "    \"Bans_gest_21 weeks postfertilization (23 weeks LMP) \": \"21\",\n",
    "    \"Bans_gest_22 weeks postfertilization (24 weeks LMP)\": \"22\",\n",
    "    \"Bans_gest_24 weeks postfertilization (26 weeks LMP)\": \"24\",\n",
    "    \"Bans_gestViability\": \"24\", #chose via google\n",
    "    \"Bans_gest_Fetus is capable of feeling pain\": \"25\", #chose via google\n",
    "    \"Bans_gest_3rd trimester\": \"28\" #chose via google\n",
    "}\n",
    "abortion_data = abortion_data.rename(columns=new_names)\n",
    "\n",
    "abortion_processed = abortion_data[['state', 'start', 'end']].copy()\n",
    "columns_to_check =  [col for col in abortion_data.columns if col not in ['State', 'Start', 'End']]\n",
    "abortion_processed['latest_abortion'] = abortion_data[columns_to_check].apply(\n",
    "    lambda row: next((int(col) for col in columns_to_check if str(row[col]) == \"1\"), 40), axis=1)\n",
    "\n",
    "abortion_processed['start'] = pd.to_datetime(abortion_processed['start'])\n",
    "abortion_processed['end'] = pd.to_datetime(abortion_processed['end'])\n",
    "abortion_processed['year'] = abortion_processed['start'].dt.year\n",
    "abortion_processed['length'] = (abortion_processed['end'] - abortion_processed['start']).dt.days\n",
    "abortion_processed = abortion_processed.loc[abortion_processed.groupby(['state', 'year'])['length'].idxmax()]\n",
    "abortion_processed = abortion_processed.drop(columns=['start', 'end', 'length'])\n",
    "\n",
    "abortion_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31bbf748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state              0\n",
      "latest_abortion    0\n",
      "year               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latest_abortion</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.598540</td>\n",
       "      <td>2019.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.328758</td>\n",
       "      <td>1.647206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latest_abortion         year\n",
       "count       137.000000   137.000000\n",
       "mean         25.598540  2019.729927\n",
       "std          10.328758     1.647206\n",
       "min           4.000000  2018.000000\n",
       "25%          20.000000  2018.000000\n",
       "50%          20.000000  2019.000000\n",
       "75%          40.000000  2021.000000\n",
       "max          40.000000  2022.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(abortion_processed.isna().sum(axis=0))\n",
    "abortion_processed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae04e9c",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**:\n",
    "\n",
    "**Imbalance**:\n",
    "\n",
    "**Scaling**:\n",
    "\n",
    "**Other**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understand and describe the preprocessing required such that data is in a form amenable to later downstream tasks such as visualizing and modeling, as is appropriate to the specific project goals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e8d54",
   "metadata": {},
   "source": [
    "One of our biggest considerations is that our predictor variables, X, is essentially 3d (reshaped), not 2d. We are looking at a bunch of predictors **over state** and **over time**. This might make our predictions complicated, especially because we are trying to see **why** fertility is changing over time (so the reason that there are less babies in 2022 can't simply be that it is 2022). Thus, it might make more sense to choose only **one year** to regress on. Also, it may be hard to **visualize** multiple years and states simultaniously as, for example, if we drew a map and colored each state by predictor category, we would have to choose one specific time to do so (and vice versa).  PLEASE LET US KNOW WHAT YOU THINK!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0aff50",
   "metadata": {},
   "source": [
    "It also may make sense to just try to minimize predictors in general as we don't want to get too specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b047880",
   "metadata": {},
   "source": [
    "### This is how we envision generally preprocessing..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> expected_url = './data/html/screenboston.html'\n>>> assert os.path.isfile(expected_url), f'Expected local file {expected_url}'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> expected_url = './data/html/screenboston.html'\n>>> with open(expected_url, 'r') as f:\n...     content = f.read()\n...     s = BeautifulSoup(content)\n...     assert s.select_one('p').text == 'Screen Boston', f'Content of file saved from {expected_url} should contain a <p> tag with the page name.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n = 50\n>>> assert len(movies) > n, f'`movies` should contain more than {n} elements; you have {len(movies)}.'\n>>> assert all((isinstance(m, dict) for m in movies)), 'Elements of `movies` should all be dictionaries.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> keys = {'title', 'directors', 'year', 'genre', 'runtime', 'theater', 'screen_date', 'screen_times'}\n>>> assert all((set(keys).issubset(m.keys()) for m in movies)), f'Each dictionary in `movies` should contain all of these keys: {', '.join(keys)}. At least one dictionary is missing one or more keys.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> assert all((isinstance(m['year'], int) for m in movies)), \"The 'year' value should be an integer in all dictionaries.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> snapshots = glob.glob('./data/html/snapshot_*.html')\n>>> assert len(snapshots) >= 4, f'You should have at least 4 snapshots, but found {len(snapshots)} files with paths like ./data/html/snapshot_*.html'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> snapshots = glob.glob('./data/html/snapshot_*.html')\n>>> assert all((re.match('snapshot_\\\\d{8}\\\\.html', os.path.basename(f)) for f in snapshots)), \"All snapshot files should be named in the format 'snapshot_YYYYMMDD.html'\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert os.path.isfile('data/movies.json'), \"The file 'data/movies.json' should exist.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> with open('data/movies.json', 'r') as f:\n...     movies = json.load(f)\n>>> n = 300\n>>> assert len(movies) > n, f'`movies` should now contain more than {n} elements; you have {len(movies)}.'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> keys = {'title', 'directors', 'year', 'genre', 'runtime', 'theater', 'screen_date', 'screen_times'}\n>>> assert all((isinstance(m, dict) and set(keys).issubset(m.keys()) for m in movies)), f'Each dictionary in `movies` should contain all of these keys: {', '.join(keys)}. At least one dictionary is missing one or more keys.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(df, pd.DataFrame), \"You should have stored your DataFrame in a variable called 'df'\"\n>>> assert df.shape[1] == 8, 'Your DataFrame, df, should have 8 columns'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> assert df.shape[0] > 300, 'You should have found at least 300 non-duplicate rows'\n>>> assert df.shape[0] == df.drop_duplicates().shape[0], 'There are still duplicate rows in your DataFrame'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> def is_datetime_column_hacky(column):\n...     dtype_str = str(column.dtype)\n...     valid_types = ['date', 'timestamp', 'timedelta', 'duration']\n...     return any((t in dtype_str.lower() for t in valid_types))\n>>> assert is_datetime_column_hacky(df['screen_date']), \"The 'screen_date' column must be either a Pandas or PyArrow date/datetime type.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> def is_datetime_column_hacky(column):\n...     dtype_str = str(column.dtype)\n...     valid_types = ['date', 'timestamp', 'timedelta', 'duration']\n...     return any((t in dtype_str.lower() for t in valid_types))\n>>> assert is_datetime_column_hacky(df['runtime']), \"The 'runtime' column must be either a Pandas or PyArrow timedelta type.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert df['screen_date'].is_monotonic_increasing, \"The 'screen_date' column is not sorted in ascending order\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 7,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'wiki_id' in df.columns, \"`df` should now have a column called 'wiki_id'.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> p = 0.5\n>>> assert (q := df['wiki_id'].notna().mean()) >= p, f'You should have been able to find wiki IDs for at least {p:.0%} of the screenings. You found {q:.0%}.'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'wiki_html' in df.columns, \"`df` should now have a column called 'wiki_html'.\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = 0.5\n>>> assert (q := df['wiki_html'].notna().mean()) >= p, f'You should have been able to acquire wiki page HTML content for at least {p:.0%} of the screenings. You found {q:.0%}.'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "wrapup": {
     "name": "wrapup",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(hours_spent_on_hw), 'Please select a time in hours (int or float) to specify how long you spent on this assignment.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
