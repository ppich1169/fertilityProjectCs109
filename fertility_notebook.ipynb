{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1586e42",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7423c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d882ae3",
   "metadata": {},
   "source": [
    "Please note, we will be collaborating via Git. Please find our project at https://github.com/ppich1169/fertilityProjectCs109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461283f",
   "metadata": {},
   "source": [
    "# Milestone 1: Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07556bb7",
   "metadata": {},
   "source": [
    "Over the past fifty years, fertility rates in the US have plummeted and are currently at a historic low. Conversations about why fertility has fallen so substantially and how we can address the implications of this shift for government programs like social security have been quite salient in recent public discourse and in the 2024 election cycle. \n",
    "\n",
    "Interestingly, there is significant variation in fertility rates across US states. We’d like to understand the relative importance of various factors in determining a state’s fertility rate. \n",
    "\n",
    "We plan to run a multiple regression of fertility rate (can get state-by-state here from the CDC’s National Center for Health Statistics) on a number of regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d422fe2",
   "metadata": {},
   "source": [
    "**Goal:** Create a regression that can predict the fertility rate of a state. Then, analyze coefficients and/or use causal inference to understand why fertility rate is going down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2306c",
   "metadata": {},
   "source": [
    "# Milestone 2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091b7ea",
   "metadata": {},
   "source": [
    "## 1. Access the data that you will be using for the final project by downloading, collecting, or scraping* from the relevant source(s) and 2. Load the data into a Jupyter notebook and understand the data by examining, among other characteristics of interest, data missingness, imbalance, and scaling issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6af71",
   "metadata": {},
   "source": [
    "### Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ab7e9",
   "metadata": {},
   "source": [
    "Our response variable is **fertility rate by state over time** which can be found at https://www.cdc.gov/nchs/pressroom/sosmap/fertility_rate/fertility_rates.htm. \n",
    "\n",
    "We accessed it via download and saved it as `fertility_rate_census.csv`. \n",
    "\n",
    "Please note, fertility rate is defined as  **total number of births per 1,000 women aged 15-44** and our dataset looks at fertility rate for each of the 50 states over 9 years (2014-2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4bfa7",
   "metadata": {},
   "source": [
    "### Predictors\n",
    "_We used our previous knowledge and assumptions to create an **X** dataset of predictors that we believe may influence fertility rates_\n",
    "\n",
    "Because fertility rate is evaluated statewide , and states vary significantly in population size, we have decided that for all of the predictors, we are going to essentially **normalize** them by looking at the percentage of each state that fall into a specific category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28728668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR              0\n",
      "STATE             0\n",
      "FERTILITY RATE    0\n",
      "BIRTHS            0\n",
      "URL               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>FERTILITY RATE</th>\n",
       "      <th>BIRTHS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.008869</td>\n",
       "      <td>60.057871</td>\n",
       "      <td>75783.962306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.588850</td>\n",
       "      <td>6.420758</td>\n",
       "      <td>86837.134690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>44.300000</td>\n",
       "      <td>5133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>21758.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>60.200000</td>\n",
       "      <td>55971.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>86486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>502879.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              YEAR  FERTILITY RATE         BIRTHS\n",
       "count   451.000000      451.000000     451.000000\n",
       "mean   2018.008869       60.057871   75783.962306\n",
       "std       2.588850        6.420758   86837.134690\n",
       "min    2014.000000       44.300000    5133.000000\n",
       "25%    2016.000000       56.000000   21758.500000\n",
       "50%    2018.000000       60.200000   55971.000000\n",
       "75%    2020.000000       63.500000   86486.000000\n",
       "max    2022.000000       80.000000  502879.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertility_rate = pd.read_csv('data/fertility_rate_census.csv')\n",
    "print(fertility_rate.isna().sum(axis=0))\n",
    "fertility_rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca340f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>YEAR</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "YEAR                  2014  2015  2016  2017  2018  2019  2020  2021  2022\n",
       "STATE                                                                     \n",
       "District of Columbia   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  57.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_fertility = fertility_rate.pivot(index='STATE', columns='YEAR', values='FERTILITY RATE')\n",
    "pivoted_fertility[pivoted_fertility.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656d151",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**: While there is no empty cell in the original dataset, we see if we pivot it by year, Washington DC only shows up in 2022. We can simply delete this row as Washington DC isn't technically a state. This is Missing at Random because we know the reason there was no Washington DC from 2014-2021 is that DC isn't considered a state\n",
    "\n",
    "**Imbalance**: Since we aren't looking at different classes there is no imbalance\n",
    "\n",
    "**Scaling**: By considering Fertility Rate (and not Number of Births), we are essentially normalizing our data as we are dividing it by total population. This will be enough in order to scale the data as it takes into account the populations of each state such that no state is overly weighed. In addition, since fertility rate is a response variable, not a predictor, we don't have to consider how large our data is in relation to other variables. Thus, we don't have to scale it any further.\n",
    "\n",
    "**Other**: We need to encode the state variable as categorical if it will be used in modeling by creating dummy variables or one-hot encoding. This issue will be true for all datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0005638",
   "metadata": {},
   "source": [
    "**CENSUS DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6b619",
   "metadata": {},
   "source": [
    "We collected essential demographic data from the Census Bureau  to analyze important trends across the U.S. population. Key indicators included race, socioeconomic status (using the Supplemental Poverty Measure, or SPM, to capture household income and the percentage of households below the poverty line), education level (representing different shares of educational attainment), and immigration status (percentage of foreign-born individuals). We also included age, sex, year, and state to enable aggregation across different regions and demographics for a more comprehensive analysis.\n",
    "\n",
    "We accessed this data by downloading it from the website, cleaned it, and and organized it into several data frames—foreignborn_df, SPM_df, race_df, and education_df—within our data folder, facilitating clear segmentation of data sources for efficient management and analysis. For socioeconomic status, we utilized the ACS SPM (Supplemental Poverty Measure) State tables from the U.S. Census Bureau, which offered a broader measure of poverty than the traditional poverty threshold. The SPM accounts for not only cash income but also non-cash benefits, such as food assistance, as well as necessary expenses like taxes and healthcare costs. This data allowed us to estimate the percentage of households below the poverty line, providing a critical indicator of financial need at the state level.\n",
    "\n",
    "To assess immigration, we utilized the percentage of foreign-born populations by state for 2022, sourced from Statista and aggregated from Census Bureau data. This data, while informative, is limited by its aggregated format, representing only documented immigrants and potentially underrepresenting undocumented populations. Our education data, also from the Census Bureau, included different shares of educational attainment across age groups, rather than focusing solely on high school graduates. We calculated weighted percentages of each educational level by state to accurately reflect the distribution of education within different populations, adjusting these percentages by each state’s total population to ensure comparability. Our race data, sourced from the Census Bureau, maintained consistency across data frames for accuracy and comparability.\n",
    "\n",
    "In processing and cleaning the data, we standardized variables such as age, sex, year, and state across all data frames, enabling seamless aggregation. Additionally, it is important to mention there are potential discrepancies, particularly the immigration and education data due to inherent limitations in coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5ed9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path pattern to load all \"education.csv\" files in the 'data' folder\n",
    "file_pattern = \"data/*education.csv\"\n",
    "all_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize empty list to collect data frames\n",
    "df_list = []\n",
    "\n",
    "# Process each education file\n",
    "for file in all_files:\n",
    "    # Extract year from the file name (assuming the format 'YYYYeducation.csv')\n",
    "    year = file.split('/')[-1][:4]\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Drop \"Population 25 years and over\" and the nine rows following it\n",
    "    pop_25_index = df[df.iloc[:, 0] == \"Population 25 years and over\"].index\n",
    "    if not pop_25_index.empty:\n",
    "        df = df.drop(index=range(pop_25_index[0], pop_25_index[0] + 10)).reset_index(drop=True)\n",
    "\n",
    "    # Identify the first column name dynamically (the label column)\n",
    "    label_column = df.columns[0]\n",
    "\n",
    "    # Keep only the first column (label) and columns ending with \"!!Percent Females!!Estimate\"\n",
    "    columns_to_keep = [label_column] + [col for col in df.columns if col.endswith(\"!!Percent Females!!Estimate\")]\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # List to store processed data\n",
    "    selected_data = []\n",
    "\n",
    "    # Process each age group section to calculate weighted averages\n",
    "    current_population = None\n",
    "    total_population = 0  # To accumulate total population for the age group\n",
    "    for index, row in df.iterrows():\n",
    "        label = row[label_column]\n",
    "\n",
    "        # Check if row represents a population group (e.g., \"Population 18 to 24 years\")\n",
    "        if \"Population\" in label:\n",
    "            # Extract population number from label and set as current population group\n",
    "            try:\n",
    "                total_population = int(label.split()[1]) if label.split()[1].isdigit() else None\n",
    "            except ValueError:\n",
    "                total_population = None\n",
    "            current_population = total_population  # Set total for this age group\n",
    "        elif current_population and \"Percent\" not in label:\n",
    "            # Calculate weighted value for educational attainment percentages based on the total population\n",
    "            for col in df.columns[1:]:  # Exclude the label column\n",
    "                # Extract the state name from the column title\n",
    "                state = col.split(\"!!\")[0]\n",
    "                \n",
    "                # Get the percentage as a string and convert to a numeric type\n",
    "                percent_str = row[col]\n",
    "\n",
    "                try:\n",
    "                    # Attempt to convert percent_str to a float, after stripping % and whitespace\n",
    "                    percent = float(str(percent_str).replace(\"%\", \"\").strip()) if percent_str else None\n",
    "                except ValueError:\n",
    "                    percent = None  # Set as None if conversion fails\n",
    "\n",
    "                # Perform calculation only if percent is not None\n",
    "                if percent is not None:\n",
    "                    scaled_value = (percent / 100) * total_population\n",
    "                else:\n",
    "                    scaled_value = None\n",
    "\n",
    "                # Append the result to selected_data\n",
    "                selected_data.append({\n",
    "                    \"Label\": label,\n",
    "                    \"Year\": year,\n",
    "                    \"State\": state,\n",
    "                    \"Female Estimate\": scaled_value,\n",
    "                    \"Population\": total_population\n",
    "                })\n",
    "\n",
    "    # Convert selected_data list into a DataFrame and append to df_list\n",
    "    temp_df = pd.DataFrame(selected_data)\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "# Combine all data frames into a single data frame\n",
    "education_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Drop rows where \"Female Estimate\" is NaN\n",
    "education_df.dropna(subset=[\"Female Estimate\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f812ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path pattern to load all \"race.csv\" files with a year prefix in the 'data' folder\n",
    "file_pattern = \"data/*race.csv\"\n",
    "all_files = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize an empty list to collect data frames\n",
    "df_list = []\n",
    "\n",
    "# Loop through all matching files\n",
    "for file_path in all_files:\n",
    "    # Extract the year from the file name (assuming it is the first part of the file name)\n",
    "    year = file_path.split('/')[-1].split('race')[0]\n",
    "    \n",
    "    try:\n",
    "        # Load the CSV file, skipping the first two lines and using comma as the delimiter\n",
    "        df = pd.read_csv(file_path, skiprows=2, delimiter=',')\n",
    "        \n",
    "        # Add the year column\n",
    "        df['Year'] = year\n",
    "        \n",
    "        # Drop columns with specific names if they exist\n",
    "        columns_to_drop = ['American Indian or Alaska Native', 'Native Hawaiian or Pacific Islander', 'Total', 'Footnotes']\n",
    "        df = df.loc[:, ~df.columns.str.contains('|'.join(columns_to_drop), na=False)]\n",
    "        \n",
    "        # Remove rows with \"United States\" in the first column\n",
    "        df = df[~df.iloc[:, 0].str.strip().str.lower().eq(\"united states\")]\n",
    "        \n",
    "        # Remove rows where \"White\" is NaN\n",
    "        df = df.dropna(subset=[\"White\"])\n",
    "        \n",
    "        # Append the cleaned dataframe to the list\n",
    "        df_list.append(df)\n",
    "    \n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Could not parse {file_path}. Skipping this file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with file {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "race_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e892e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and examine its structure\n",
    "file_path = 'data/SPM.csv'\n",
    "SPM_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18d30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and examine its structure\n",
    "file_path = 'data/foreignborn2022.csv'\n",
    "\n",
    "# Reload the CSV file as a single column and then split based on the tab delimiter\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Split the single column by tab to separate into \"State\" and \"Percent\"\n",
    "df[['State', 'Percent']] = df[0].str.split('\\t', expand=True)\n",
    "\n",
    "# Drop the original combined column\n",
    "foreignborn_df = df[['State', 'Percent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e521c",
   "metadata": {},
   "source": [
    "We also care about religion, political makeup, and whether certain abortion laws are in place (all of which are not in the census). We will find them different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006199e",
   "metadata": {},
   "source": [
    "**RELIGION DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576fc93",
   "metadata": {},
   "source": [
    "We decided to determine people's **religiousness** based off of a state's adherence rate (number of people who adhere to their religion across 1000 ) which can be found at (https://www.thearda.com/us-religion/maps/us-state-maps)\n",
    "\n",
    "We accessed it by webscraping and saved it in `religion_data.csv` in our data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2020 = \"https://www.thearda.com/us-religion/maps/us-state-maps\"\n",
    "url2010 = \"https://www.thearda.com/us-religion/maps/us-state-maps?color=orange&m1=2_2_9999_2010\"\n",
    "url2000 = \"https://www.thearda.com/us-religion/maps/us-state-maps?color=orange&m1=2_2_9999_2000\"\n",
    "response = requests.get(url2000)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "    \n",
    "script_tag = soup.find('script', text=re.compile(r'usa_map_div299992000_data = '))\n",
    "script_content = script_tag.string\n",
    "start_index = script_content.find('usa_map_div299992000_data =')\n",
    "semicolon_index = script_content.find(';', start_index)\n",
    "mapData = script_content[start_index:semicolon_index]\n",
    "\n",
    "quoted_strings = re.findall(r'\"(.*?)\"', mapData)\n",
    "values_strings = re.findall(r'(\\d+\\.\\d+)', mapData)\n",
    "year = []\n",
    "for i in range(len(values_strings)):\n",
    "    year.append(2000)\n",
    "\n",
    "last_two_chars = [s[-2:] for s in quoted_strings]\n",
    "print(last_two_chars)\n",
    "print(len(values_strings))\n",
    "\n",
    "file_paths = [\n",
    "    'data/AllReligionAdherence_2000.csv',\n",
    "    'data/AllReligionAdherence_2010.csv',\n",
    "    'data/AllReligionAdherence_2020.csv'\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    year = file_name.split('_')[-1].split('.')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Year'] = year\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427dec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State                      0\n",
      "Adherence Rate per 1000    0\n",
      "Year                       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adherence Rate per 1000</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>489.381569</td>\n",
       "      <td>2010.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.640693</td>\n",
       "      <td>8.19178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>272.190000</td>\n",
       "      <td>2000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>414.860000</td>\n",
       "      <td>2000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>492.770000</td>\n",
       "      <td>2010.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>555.040000</td>\n",
       "      <td>2020.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>791.060000</td>\n",
       "      <td>2020.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Adherence Rate per 1000        Year\n",
       "count               153.000000   153.00000\n",
       "mean                489.381569  2010.00000\n",
       "std                 101.640693     8.19178\n",
       "min                 272.190000  2000.00000\n",
       "25%                 414.860000  2000.00000\n",
       "50%                 492.770000  2010.00000\n",
       "75%                 555.040000  2020.00000\n",
       "max                 791.060000  2020.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_data = pd.read_csv('data/religion_data.csv')\n",
    "print(religion_data.isna().sum(axis=0))\n",
    "religion_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4e3df",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**: After webscraping ARDA, there are no missing values in any cells, but definitely in the number of years (153 vs 451 above). This is because this index is only calculated every 10 years (2000, 2010, 2020). We have to decide how we want to impute this data. One option is to create a line going through the 2000, 2010, and 2020 datapoints, and then impute the data that would sit on this line for 2011-2019 and 2021-2022. \n",
    "\n",
    "**Imbalance**: Although the actual number of state datapoints are equal and fine, the source of the imbalance stems from which religions do these data sets stem from. All the main categories listed on the Association of Religious Digital Archives are branches of Christianity. I have no idea if these are actually the most popular religions in the US or is the source biased towards it.\n",
    "\n",
    "**Scaling**: Since adherence rates range widely (e.g., from 272.19 to 791.06), standardizing or normalizing values might be beneficial, particularly if this data will be used for machine learning or statistical modeling. Standardization (e.g., Z-score) could be applied if you want each adherence rate centered around zero, while min-max normalization scales values between a range like [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b77098",
   "metadata": {},
   "source": [
    "**POLITICS DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ce4a9",
   "metadata": {},
   "source": [
    "We decided to determine people's political orienation based off of the Cook Partisan Voting Index (Cook PVI), which is a measure of each state's political leaning relative to the nation as a whole.\n",
    "\n",
    "The primary challenge with using this index is that the methodology was switched in 2022 to weigh the last presidential election 0.75 and the second to last 0.25, as opposed to the even (50/50) weighting of both years that was used in prior years. We will either figure out how to reweight the outcomes based on the raw data if we can get it or exclude 2022 from our analysis.\n",
    "\n",
    "The calculation of the index is described in more detail here: https://www.cookpolitical.com/cook-pvi\n",
    "\n",
    "We will follow a similar methodology to that used in \"State-level Political Partisanship Strongly Correlates with Health Outcomes for US Children,\" (full citation below).* We converted the PVI's to numerical values, with negative values representing Democratic PVIs and positive numbers representing Republican ones (an arbitrary choice). Then, we scaled those values with sklearn's MinMaxScaler() so that states have a rating between 0 and 1 representing how conservative they are, with 1 being most conservatve and 0 being most liberal.\n",
    "\n",
    "We accessed the data for 2022 from this source: https://datawrapper.dwcdn.net/0djXs/2/ and saved it in cook_pvi_2022.csv in our data folder. We tried scraping the website but the data is not in the html but instead pulled from a source so we were unable to access the data using the same strategy as HW 1.\n",
    "\n",
    "*Paul, M., Zhang, R., Liu, B. et al. State-level political partisanship strongly correlates with health outcomes for US children. Eur J Pediatr 181, 273–280 (2022). https://doi.org/10.1007/s00431-021-04203-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade7e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State           0\n",
      "2022_PVI        0\n",
      "2020_Biden      0\n",
      "2020_Trump      0\n",
      "2016_Clinton    0\n",
      "2016_Trump      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>2022_PVI</th>\n",
       "      <th>2020_Biden</th>\n",
       "      <th>2020_Trump</th>\n",
       "      <th>2016_Clinton</th>\n",
       "      <th>2016_Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>R+11</td>\n",
       "      <td>49.50%</td>\n",
       "      <td>48.80%</td>\n",
       "      <td>27.50%</td>\n",
       "      <td>45.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State 2022_PVI 2020_Biden 2020_Trump 2016_Clinton 2016_Trump\n",
       "count        51       51         51         51           51         51\n",
       "unique       51       30         50         48           48         48\n",
       "top     Alabama     R+11     49.50%     48.80%       27.50%     45.50%\n",
       "freq          1        3          2          2            2          2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_df = pd.read_csv('data/cook_pvi_2022.csv')\n",
    "print(pol_df.isna().sum(axis=0))\n",
    "pol_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0a8dc",
   "metadata": {},
   "source": [
    "**ABORTION DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98418d",
   "metadata": {},
   "source": [
    "We decided to determine state's **abortion laws** based off of how late into pregnancy, abortion is legally allowed which can be found at https://lawatlas.org/datasets/abortion-bans. We chose this dataset because it is the only one on the internet showing abortion bans in the 2014-2022 time frame and how they change (most just show abortion bans now)\n",
    "\n",
    "We accessed it by downloading it, converting from xlsx to csv, and saved it in `abortion_data.csv` in our data folder\n",
    "\n",
    "The main thing to consider is that **just because abortion is legal, doesn't mean it is accessible**. Many states may technically allow abortion but only have one clinic, so its not attainable. That said, we have chosen this metric (when is abortion legal), to coincide with current political debate about whether abortion should be legalized. \n",
    "\n",
    "There will be significant preprocessing required as the data is in format `Effective Date`, `Valid Through Date` for each law which must simply be converted into year (whichever law was the majority of the year), and each ban `6 weeks`, `8 weeks` etc is categorical! It would make more sense to simply make a variable listing the latest week aborition is legal (0,6,8,12,52 etc).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a71fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_data = pd.read_csv('data/abortion_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0e8bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>latest_abortion</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>20</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  latest_abortion  year\n",
       "0  Alabama               20  2018\n",
       "2  Alabama               20  2019\n",
       "3  Alabama               20  2022\n",
       "4   Alaska               40  2018\n",
       "5  Arizona               18  2018"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"State\",\"Effective Date\",\"Valid Through Date\",\"Bans_gest_4 weeks postfertilization (6 weeks LMP) \" ,\"Bans_gest_6 weeks postfertilization (8 weeks LMP) \" ,\"Bans_gest_8 weeks postfertilization (10 weeks LMP)\",\"Bans_gest_10 weeks postfertilization (12 weeks LMP) \" ,\"Bans_gest_12 weeks postfertilization (14 weeks LMP)\",\"Bans_gest_13 weeks postfertilization (15 weeks LMP)\",\"Bans_gest_16 weeks postfertilization (18 weeks LMP) \",\"Bans_gest_18 weeks postfertilization (20 weeks LMP)\",\"Bans_gest_19 weeks postfertilization (21 weeks LMP)\",\"Bans_gest20 weeks postfertilization (22 weeks LMP)\",\"Bans_gest_21 weeks postfertilization (23 weeks LMP) \" ,\"Bans_gest_22 weeks postfertilization (24 weeks LMP)\",\"Bans_gest_24 weeks postfertilization (26 weeks LMP)\",\"Bans_gestViability\",\"Bans_gest_Fetus is capable of feeling pain\",\"Bans_gest_3rd trimester\"]\n",
    "abortion_data = abortion_data[columns]\n",
    "new_names = {\n",
    "    \"State\": \"state\",\n",
    "    \"Effective Date\": \"start\",\n",
    "    \"Valid Through Date\": \"end\",\n",
    "    \"Bans_gest_4 weeks postfertilization (6 weeks LMP) \": \"4\",\n",
    "    \"Bans_gest_6 weeks postfertilization (8 weeks LMP) \": \"6\",\n",
    "    \"Bans_gest_8 weeks postfertilization (10 weeks LMP)\": \"8\",\n",
    "    \"Bans_gest_10 weeks postfertilization (12 weeks LMP) \": \"10\",\n",
    "    \"Bans_gest_12 weeks postfertilization (14 weeks LMP)\": \"12\",\n",
    "    \"Bans_gest_13 weeks postfertilization (15 weeks LMP)\": \"13\",\n",
    "    \"Bans_gest_16 weeks postfertilization (18 weeks LMP) \": \"16\",\n",
    "    \"Bans_gest_18 weeks postfertilization (20 weeks LMP)\": \"18\",\n",
    "    \"Bans_gest_19 weeks postfertilization (21 weeks LMP)\": \"19\",\n",
    "    \"Bans_gest20 weeks postfertilization (22 weeks LMP)\": \"20\",\n",
    "    \"Bans_gest_21 weeks postfertilization (23 weeks LMP) \": \"21\",\n",
    "    \"Bans_gest_22 weeks postfertilization (24 weeks LMP)\": \"22\",\n",
    "    \"Bans_gest_24 weeks postfertilization (26 weeks LMP)\": \"24\",\n",
    "    \"Bans_gestViability\": \"24\", #chose via google\n",
    "    \"Bans_gest_Fetus is capable of feeling pain\": \"25\", #chose via google\n",
    "    \"Bans_gest_3rd trimester\": \"28\" #chose via google\n",
    "}\n",
    "abortion_data = abortion_data.rename(columns=new_names)\n",
    "\n",
    "abortion_processed = abortion_data[['state', 'start', 'end']].copy()\n",
    "abortion_processed['latest_abortion'] = abortion_data[abortion_data.columns].apply(\n",
    "    lambda row: next((int(col) for col in abortion_data.columns  if str(row[col]) == \"1\"), 40), axis=1)\n",
    "\n",
    "abortion_processed['start'] = pd.to_datetime(abortion_processed['start'])\n",
    "abortion_processed['end'] = pd.to_datetime(abortion_processed['end'])\n",
    "abortion_processed['year'] = abortion_processed['start'].dt.year\n",
    "abortion_processed['length'] = (abortion_processed['end'] - abortion_processed['start']).dt.days\n",
    "abortion_processed = abortion_processed.loc[abortion_processed.groupby(['state', 'year'])['length'].idxmax()]\n",
    "abortion_processed = abortion_processed.drop(columns=['start', 'end', 'length'])\n",
    "\n",
    "abortion_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48364824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state              0\n",
      "latest_abortion    0\n",
      "year               0\n",
      "dtype: int64\n",
      "missing from entire dataframe 113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latest_abortion</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.598540</td>\n",
       "      <td>2019.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.328758</td>\n",
       "      <td>1.647206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latest_abortion         year\n",
       "count       137.000000   137.000000\n",
       "mean         25.598540  2019.729927\n",
       "std          10.328758     1.647206\n",
       "min           4.000000  2018.000000\n",
       "25%          20.000000  2018.000000\n",
       "50%          20.000000  2019.000000\n",
       "75%          40.000000  2021.000000\n",
       "max          40.000000  2022.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(abortion_processed.isna().sum(axis=0))\n",
    "print(\"missing from entire dataframe\", 50*5-len(abortion_processed))\n",
    "abortion_processed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3dece",
   "metadata": {},
   "source": [
    "Things to Consider:\n",
    "\n",
    "**Missingness**: We see while there are no null cells in our dataset, there are 113 \"missing cells\" from what would be expected (one for every state for every year). This is simply because of how our dataset was made -- there is only a new row if a new law is enacted (not one per year). Thus, if we are missing a row for a certain year, we can simply **impute** the data by copying the previous row. \n",
    "\n",
    "**Imbalance**: There is no imbalance as there is no population sampling. \n",
    "\n",
    "**Scaling**: We don't need to scale the data by itself but might scale data as a whole later so they don't have stds that are too high. \n",
    "\n",
    "**Other**: We decided to change our data from a 1-hot encoded dataset, to 1 quantitative varaible. We did this because there seems to be a clear relatonship between the previously encoded categories (a 10 week ban is stronger than a 15 week ban and less strong than a 4 week ban). Thus, we made it ordinal. In additon, note that if there was no abortion ban, we arbitrarily set this ordinal variable to 40, the length of the average pregancy. It might make some sense to add an **indicator variable** to be 0 if there is no abortion ban at all (40 weeks) and 1 if there is an abortion ban. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87cb5b",
   "metadata": {},
   "source": [
    "Some issues we preliminary have considered before even inspecting the data includes:\n",
    "\n",
    "\n",
    "- **under reporting immigration status**: via google, people tend to underreport whether they are immigrants. This is potentially a missingness issue\n",
    "\n",
    "-  **multicollinearity**: There is most likely a relationship between racial background / household income and an individual's birth country (immigration status) so we can't use both as predictors in the same equation. We don't know how strong this correlation will be so are not worried yet, but would love to talk about it with a TF\n",
    "\n",
    "- **is this just too much data??**: looking at each of these attributes for each state for each year may just be too many dimensions. Is there really a big difference accross years? Should we just look at 1? If so, which? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef9b79",
   "metadata": {},
   "source": [
    "## 3. Understand and describe the preprocessing required such that data is in a form amenable to later downstream tasks such as visualizing and modeling, as is appropriate to the specific project goals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e8d54",
   "metadata": {},
   "source": [
    "One of our biggest considerations is that our predictor variables, X, is essentially 3d (reshaped), not 2d. We are looking at a bunch of predictors **over state** and **over time**. This might make our predictions complicated, especially because we are trying to see **why** fertility is changing over time (so the reason that there are less babies in 2022 can't simply be that it is 2022). Thus, it might make more sense to choose only **one year** to regress on. Also, it may be hard to **visualize** multiple years and states simultaniously as, for example, if we drew a map and colored each state by predictor category, we would have to choose one specific time to do so (and vice versa).  PLEASE LET US KNOW WHAT YOU THINK!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0aff50",
   "metadata": {},
   "source": [
    "It also may make sense to just try to minimize predictors in general as we don't want to get too specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b047880",
   "metadata": {},
   "source": [
    "### This is how we envision generally preprocessing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5c084",
   "metadata": {},
   "source": [
    "Below is the preprocessing for political data. We scale the Cook PVI scores to be on a scale of 0 to 1, where 1 is most conservative and 0 is least conservative. We drop DC because it is not a state. There is no missingness in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea028b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(-16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop DC because it's not a state: \n",
    "pol_df = pol_df[pol_df['State'] != 'District of Columbia']\n",
    "pol_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "unscaled_ratings=[]\n",
    "for i in range(len(pol_df)):\n",
    "    magnitude = re.search(r\"(?<=\\+).*\", pol_df['2022_PVI'][i])\n",
    "    magnitude = int(magnitude.group())\n",
    "    \n",
    "    if pol_df['2022_PVI'][i][0] == 'R':\n",
    "        unscaled_ratings.append(magnitude)\n",
    "    else:\n",
    "        unscaled_ratings.append(magnitude * -1)\n",
    "\n",
    "pol_df['unscaled_rating'] = unscaled_ratings\n",
    "\n",
    "pol_rating_scaler = MinMaxScaler()\n",
    "scaled_pol_ratings = pol_rating_scaler.fit_transform(pol_df['unscaled_rating'].values.reshape(-1, 1))\n",
    "\n",
    "pol_df['scaled_rating'] = scaled_pol_ratings\n",
    "pol_df.head()\n",
    "\n",
    "pol_df['unscaled_rating'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a031ef",
   "metadata": {},
   "source": [
    "### One way to preliminarily understand why fertility rate is decreasing is to look at where it changes over time, and think about what factors dominate those areas.... aka do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ecc0196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this accounts for 90.25 % variance\n"
     ]
    }
   ],
   "source": [
    "pivoted_fertility = fertility_rate.pivot(index='STATE', columns='YEAR', values='FERTILITY RATE')\n",
    "X_std =  StandardScaler().fit_transform(pivoted_fertility.fillna(0)) \n",
    "pca = PCA(n_components=1) \n",
    "principal_components = pca.fit_transform(X_std)\n",
    "\n",
    "states = pivoted_fertility.index\n",
    "pca_states = pd.DataFrame(data=principal_components, columns=['PC1'], index=states).reset_index()\n",
    "pca_states.columns = ['state', 'PC1']\n",
    "\n",
    "print(\"this accounts for\", np.round(100*pca.explained_variance_ratio_[0], 2), \"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d627617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "geo": "geo",
         "hovertemplate": "state=%{location}<br>Principal Component Value=%{z}<extra></extra>",
         "locationmode": "USA-states",
         "locations": [
          "AK",
          "AL",
          "AR",
          "AZ",
          "CA",
          "CO",
          "CT",
          "DE",
          "District of Columbia",
          "FL",
          "GA",
          "HI",
          "IA",
          "ID",
          "IL",
          "IN",
          "KS",
          "KY",
          "LA",
          "MA",
          "MD",
          "ME",
          "MI",
          "MN",
          "MO",
          "MS",
          "MT",
          "NC",
          "ND",
          "NE",
          "NH",
          "NJ",
          "NM",
          "NV",
          "NY",
          "OH",
          "OK",
          "OR",
          "PA",
          "RI",
          "SC",
          "SD",
          "TN",
          "TX",
          "UT",
          "VA",
          "VT",
          "WA",
          "WI",
          "WV",
          "WY"
         ],
         "name": "",
         "type": "choropleth",
         "z": [
          3.541283712977135,
          0.6709412182023973,
          1.5457949635374837,
          0.10649601868313613,
          -0.6917694677307884,
          -1.1011690210012075,
          -2.1863383716862783,
          -0.37832791196931714,
          -16.233015809645977,
          -0.528790432081549,
          -0.05460097994243515,
          1.6461409794543915,
          1.5048116278832806,
          1.9646225328459557,
          -0.5949947846694897,
          1.0685882178489023,
          1.7938455128410884,
          1.3653788074915456,
          1.8402640528169016,
          -2.7120392538854134,
          0.12559309177697608,
          -2.1222387563099274,
          -0.3141942755414467,
          1.05389380426039,
          0.749391890778195,
          1.0968872405309764,
          0.2727677589110798,
          -0.02471643195687145,
          3.890011060657697,
          2.9059396366882417,
          -2.9188544099122273,
          0.13734118876124227,
          -0.08137037564430298,
          -0.018514278358477677,
          -0.6701232387274071,
          0.5452279391799576,
          1.801088682535652,
          -2.015507684068103,
          -0.7042952458645648,
          -2.763023749367187,
          -0.09768345031071042,
          4.288426453218404,
          0.6257515800884539,
          1.7738449052948442,
          3.3577915513545573,
          -0.10421969181466428,
          -3.432102609219369,
          -0.27078633430077365,
          -0.12296469901310918,
          -0.5505104046423946,
          1.0200272390451
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmax": 5,
         "cmin": -5,
         "colorbar": {
          "title": {
           "text": "Principal Component Value"
          }
         },
         "colorscale": [
          [
           0,
           "purple"
          ],
          [
           0.5,
           "white"
          ],
          [
           1,
           "green"
          ]
         ]
        },
        "geo": {
         "center": {},
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "scope": "usa"
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "What states have the highest variation in fertility rates?"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.choropleth(\n",
    "    pca_states,\n",
    "    locations='state',\n",
    "    locationmode=\"USA-states\",\n",
    "    color='PC1',\n",
    "    scope=\"usa\",  \n",
    "    range_color=[-5,5],\n",
    "    color_continuous_scale=['purple', 'white', 'green'], \n",
    "    labels={'PC1': 'Principal Component Value'}\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text=\"What states have the highest variation in fertility rates?\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a5c55",
   "metadata": {},
   "source": [
    "We see that the first principle componetent represents 90% of varition over state and time. Thus, most of the change (net decrease) in fertility rate is seen when the coasts (purples) move strongly in one direction (presumably decrease given the net decrease) and the center of the US moves slightly in the other. We can use this information to understand what variables would be good predictors, aka the ones that match the coloring above. For example, a wealth distribution or political map would see similar differences with one color on the coast and another in the center. Thus we know that looking at household income and political affiliation are going to be really good predictor variables!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f3281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> expected_url = './data/html/screenboston.html'\n>>> assert os.path.isfile(expected_url), f'Expected local file {expected_url}'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> expected_url = './data/html/screenboston.html'\n>>> with open(expected_url, 'r') as f:\n...     content = f.read()\n...     s = BeautifulSoup(content)\n...     assert s.select_one('p').text == 'Screen Boston', f'Content of file saved from {expected_url} should contain a <p> tag with the page name.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n = 50\n>>> assert len(movies) > n, f'`movies` should contain more than {n} elements; you have {len(movies)}.'\n>>> assert all((isinstance(m, dict) for m in movies)), 'Elements of `movies` should all be dictionaries.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> keys = {'title', 'directors', 'year', 'genre', 'runtime', 'theater', 'screen_date', 'screen_times'}\n>>> assert all((set(keys).issubset(m.keys()) for m in movies)), f'Each dictionary in `movies` should contain all of these keys: {', '.join(keys)}. At least one dictionary is missing one or more keys.'\n",
         "hidden": false,
         "locked": false,
         "points": 4
        },
        {
         "code": ">>> assert all((isinstance(m['year'], int) for m in movies)), \"The 'year' value should be an integer in all dictionaries.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> snapshots = glob.glob('./data/html/snapshot_*.html')\n>>> assert len(snapshots) >= 4, f'You should have at least 4 snapshots, but found {len(snapshots)} files with paths like ./data/html/snapshot_*.html'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> snapshots = glob.glob('./data/html/snapshot_*.html')\n>>> assert all((re.match('snapshot_\\\\d{8}\\\\.html', os.path.basename(f)) for f in snapshots)), \"All snapshot files should be named in the format 'snapshot_YYYYMMDD.html'\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert os.path.isfile('data/movies.json'), \"The file 'data/movies.json' should exist.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> with open('data/movies.json', 'r') as f:\n...     movies = json.load(f)\n>>> n = 300\n>>> assert len(movies) > n, f'`movies` should now contain more than {n} elements; you have {len(movies)}.'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> keys = {'title', 'directors', 'year', 'genre', 'runtime', 'theater', 'screen_date', 'screen_times'}\n>>> assert all((isinstance(m, dict) and set(keys).issubset(m.keys()) for m in movies)), f'Each dictionary in `movies` should contain all of these keys: {', '.join(keys)}. At least one dictionary is missing one or more keys.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(df, pd.DataFrame), \"You should have stored your DataFrame in a variable called 'df'\"\n>>> assert df.shape[1] == 8, 'Your DataFrame, df, should have 8 columns'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> assert df.shape[0] > 300, 'You should have found at least 300 non-duplicate rows'\n>>> assert df.shape[0] == df.drop_duplicates().shape[0], 'There are still duplicate rows in your DataFrame'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> def is_datetime_column_hacky(column):\n...     dtype_str = str(column.dtype)\n...     valid_types = ['date', 'timestamp', 'timedelta', 'duration']\n...     return any((t in dtype_str.lower() for t in valid_types))\n>>> assert is_datetime_column_hacky(df['screen_date']), \"The 'screen_date' column must be either a Pandas or PyArrow date/datetime type.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> def is_datetime_column_hacky(column):\n...     dtype_str = str(column.dtype)\n...     valid_types = ['date', 'timestamp', 'timedelta', 'duration']\n...     return any((t in dtype_str.lower() for t in valid_types))\n>>> assert is_datetime_column_hacky(df['runtime']), \"The 'runtime' column must be either a Pandas or PyArrow timedelta type.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert df['screen_date'].is_monotonic_increasing, \"The 'screen_date' column is not sorted in ascending order\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 7,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'wiki_id' in df.columns, \"`df` should now have a column called 'wiki_id'.\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> p = 0.5\n>>> assert (q := df['wiki_id'].notna().mean()) >= p, f'You should have been able to find wiki IDs for at least {p:.0%} of the screenings. You found {q:.0%}.'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'wiki_html' in df.columns, \"`df` should now have a column called 'wiki_html'.\"\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = 0.5\n>>> assert (q := df['wiki_html'].notna().mean()) >= p, f'You should have been able to acquire wiki page HTML content for at least {p:.0%} of the screenings. You found {q:.0%}.'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "wrapup": {
     "name": "wrapup",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(hours_spent_on_hw), 'Please select a time in hours (int or float) to specify how long you spent on this assignment.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
